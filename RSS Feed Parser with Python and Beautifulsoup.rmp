<?xml version="1.0" encoding="UTF-8"?><process version="9.10.001">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="9.10.001" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="true" class="web:read_rss" compatibility="9.7.000" expanded="true" height="68" name="Read RSS Feed" width="90" x="112" y="85">
        <parameter key="url" value="https://news.google.com/rss"/>
        <parameter key="random_user_agent" value="true"/>
        <parameter key="connection_timeout" value="10000"/>
        <parameter key="read_timeout" value="10000"/>
      </operator>
      <operator activated="true" class="python_scripting:execute_python" compatibility="9.10.001" expanded="true" height="103" name="Execute Python" width="90" x="313" y="85">
        <parameter key="script" value="import pandas&#10;from bs4 import BeautifulSoup&#10;&#10;# rm_main is a mandatory function, &#10;# the number of arguments has to be the number of input ports (can be none),&#10;#     or the number of input ports plus one if &quot;use macros&quot; parameter is set&#10;# if you want to use macros, use this instead and check &quot;use macros&quot; parameter:&#10;#def rm_main(data,macros):&#10;def rm_main(data):&#10;    # strip the HTML of the feed&#10;    data['clean'] = data.Content.str.replace(r'&lt;[^&lt;&gt;]*&gt;', '', regex=True)&#10;    # some more cleanup and add a space so that the tokens don't get pushed together&#10;    data['clean'] = data.clean.str.replace(r'&amp;nbsp;', ' ', regex=True)&#10;&#10;    # use beautifulsoup&#10;    # https://matix.io/extract-text-from-webpage-using-beautifulsoup-and-python/&#10;    def clean_html(content):&#10;        soup = BeautifulSoup(content, 'html.parser')&#10;        text = soup.find_all(text=True)&#10;        output = ''&#10;        blacklist = [&#10;&#9;&#9;    '[document]',&#10;&#9;&#9;    'noscript',&#10;&#9;&#9;    'header',&#10;&#9;&#9;    'html',&#10;&#9;&#9;    'meta',&#10;&#9;&#9;    'head', &#10;&#9;&#9;    'input',&#10;&#9;&#9;    'script'&#10;&#9;&#9;    # there may be more elements you don't want, such as &quot;style&quot;, etc.&#10;&#9;&#9;]&#10;        for t in text:&#10;            if t.parent.name not in blacklist:&#10;                output += '{} '.format(t)&#10;        return output&#10;    &#9;&#9;&#10;    data['clean_bs'] = data.Content.apply(clean_html)&#10;&#10;    # output ports&#10;    return data"/>
        <parameter key="notebook_cell_tag_filter" value=""/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
        <parameter key="use_macros" value="false"/>
      </operator>
      <connect from_op="Read RSS Feed" from_port="output" to_op="Execute Python" to_port="input 1"/>
      <connect from_op="Execute Python" from_port="output 1" to_port="result 1"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
    </process>
  </operator>
</process>
